# vision_ai.py - MÃ³dulo especializado em anÃ¡lise visual automotiva usando NeuraVision
import os
import base64
import logging
from neura_ai.core import Neura
from neura_ai.config import NeuraConfig

# Sincronizado com o logger do app.py
logger = logging.getLogger(__name__)

# Prompt especializado para o modelo de visÃ£o (moondream)
VISION_PROMPT = """
VocÃª Ã© um especialista em inspeÃ§Ã£o veicular tÃ©cnica ("Raio-X MecÃ¢nico").
Analise a imagem buscando falhas ocultas e detalhes de mercado.
Identifique:
1. VeÃ­culo: Marca, modelo, ano/geraÃ§Ã£o estimada.
2. Lataria/Estrutura: Desalinhamentos de peÃ§as (indicando batidas), ferrugem.
3. MecÃ¢nica VisÃ­vel: Vazamentos, fumaÃ§a, estado dos pneus.
4. Acabamento: FarÃ³is, vidros, interior.
5. Veredito: Bom estado, Cuidado (riscos mÃ©dios) ou Bomba (riscos altos).
Seja extremamente crÃ­tico e tÃ©cnico.
"""

# Detecta o Host (Render/TÃºnel)
host_env = os.getenv("OLLAMA_HOST")

host_library = getattr(NeuraConfig, 'TUNNEL_URL', "http://localhost:11434")

host_escolhido = host_env if host_env else host_library
# Inicializa a Neura focada em visÃ£o com o host correto
brain = Neura(
    vision_model="moondream", 
    system_prompt=VISION_PROMPT,
    host=host_escolhido
)

def analisar_imagem(image_b64: str, pergunta: str | None = None, filename: str = "temp_vision_upload.png") -> str:
    """
    Analisa imagem usando Pipeline de Dois EstÃ¡gios:
    1. Moondream (VisÃ£o) extrai os dados brutos.
    2. Qwen (Linguagem) interpreta como o consultor NOG.
    """
    temp_path = filename 
    
    try:
        # 1. Decodificar e salvar temporariamente
        if "," in image_b64:
            image_b64 = image_b64.split(",")[1]
        
        raw_data = base64.b64decode(image_b64)
        with open(temp_path, "wb") as f:
            f.write(raw_data)

        # 2. ESTÃGIO 1: VISÃƒO BRUTA (Moondream)
        logger.info(f"ğŸ‘ï¸ EstÃ¡gio 1: Extraindo fatos da imagem via {brain.host}...")
        instrucao_visao = "Analyze this car for mechanical issues, rust, panel gaps, and estimated value condition."
        
        # O Core salva isso automaticamente na memÃ³ria SQLite
        fatos_da_imagem = brain.get_response(instrucao_visao, image_path=temp_path)

        # 3. ESTÃGIO 2: INTERPRETAÃ‡ÃƒO DO NOG (Qwen)
        logger.info(f"ğŸ§  EstÃ¡gio 2: NOG interpretando resultados...")

        prompt_nog = f"""
        VocÃª Ã© o NOG, consultor automotivo expert.
        Com base na anÃ¡lise visual que vocÃª acabou de realizar (memÃ³ria recente), responda:

        Pergunta do Cliente: {pergunta if pergunta else "O que vocÃª vÃª de relevante neste carro?"}

        Sua Resposta deve conter:
        1. ğŸ“‹ Resumo do Estado (Lataria, Pneus, Detalhes).
        2. ğŸ”§ Alerta MecÃ¢nico (aponte possÃ­veis problemas invisÃ­veis comuns a este modelo).
        3. ğŸ’° Estimativa de Valor (Compare com a mÃ©dia de mercado/FIPE).

        Seja direto, proteja o comprador de ciladas.
        """

        # Chamada de texto puro (aproveitando o contexto da imagem salva no SQLite)
        resposta_final = brain.get_response(prompt_nog)
        
        logger.info(f"âœ“ AnÃ¡lise completa entregue pelo NOG")
        return resposta_final

    except Exception as e:
        logger.error(f"âŒ Erro na anÃ¡lise de visÃ£o Neura: {e}", exc_info=True)
        return "âŒ O NOG nÃ£o conseguiu analisar esta imagem no momento."
    finally:
        if os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except Exception:
                pass